require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
knitr::opts_chunk$set(cache=TRUE)
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
knitr::opts_chunk$set(cache=TRUE)
install.packages(caret)
install.packages("caret")
install.packages("pbkrtest")
packageurl <- "https://cran.r-project.org/src/contrib/Archive/pbkrtest/pbkrtest_0.4-4.tar.gz" install.packages(packageurl, repos=NULL, type="source")
packageurl <- "https://cran.r-project.org/src/contrib/Archive/pbkrtest/pbkrtest_0.4-4.tar.gz" install.packages(packageurl, repos=NULL, type="source")
install.packages("caret")
install.packages("car")
packageurl <- "https://cran.r-project.org/src/contrib/Archive/pbkrtest/pbkrtest_0.4-4.tar.gz" install.packages(packageurl, repos=NULL, type="source")
install.packages(path_to_file, lib=lib,repos = NULL, type="source")
setwd("~/Practical Machine Learning - Coursera/pbkrtest")
install.packages("~/Practical Machine Learning - Coursera/pbkrtest", lib=lib,repos = NULL, type="source")
setwd("~/Practical Machine Learning - Coursera")
install.packages("~/Practical Machine Learning - Coursera", lib=lib,repos = NULL, type="source")
install.packages("~/Practical Machine Learning - Coursera/pbkrtest_0.4-4.tar.gz", repos = NULL, type = "source")
install.packages("lme4")
install.packages("~/Practical Machine Learning - Coursera/pbkrtest_0.4-4.tar.gz", repos = NULL, type = "source")
install.packages("car")
install.packages("caret")
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR()
install.packages("~/Practical Machine Learning - Coursera/car_2.1-0.tar.gz", repos = NULL, type = "source")
install.packages("caret")
install.packages("~/Practical Machine Learning - Coursera/caret_6.0-62.tar.gz", repos = NULL, type = "source")
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
knitr::opts_chunk$set(cache=TRUE)
install.packages("corrplot")
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
knitr::opts_chunk$set(cache=TRUE)
install.packages("Rtsne")
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
knitr::opts_chunk$set(cache=TRUE)
install.packages("xgboost")
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
knitr::opts_chunk$set(cache=TRUE)
require(caret)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
knitr::opts_chunk$set(cache=TRUE)
# URL of the training and testing data
train.url ="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test.url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# file names
train.name = "./data/pml-training.csv"
test.name = "./data/pml-testing.csv"
# if directory does not exist, create new
if (!file.exists("./data")) {
dir.create("./data")
}
# if files does not exist, download the files
if (!file.exists(train.name)) {
download.file(train.url, destfile=train.name, method="curl")
}
if (!file.exists(test.name)) {
download.file(test.url, destfile=test.name, method="curl")
}
# load the CSV files as data.frame
train = read.csv("./data/pml-training.csv")
test = read.csv("./data/pml-testing.csv")
dim(train)
dim(test)
names(train)
# target outcome (label)
outcome.org = train[, "classe"]
outcome = outcome.org
levels(outcome)
# convert character levels to numeric
num.class = length(levels(outcome))
levels(outcome) = 1:num.class
head(outcome)
# remove outcome from train
train$classe = NULL
# filter columns on: belt, forearm, arm, dumbell
filter = grepl("belt|arm|dumbell", names(train))
train = train[, filter]
test = test[, filter]
# remove columns with NA, use test data as referal for NA
cols.without.na = colSums(is.na(test)) == 0
train = train[, cols.without.na]
test = test[, cols.without.na]
# check for zero variance
zero.var = nearZeroVar(train, saveMetrics=TRUE)
zero.var
featurePlot(train, outcome.org, "strip")
corrplot.mixed(cor(train), lower="circle", upper="color",
tl.pos="lt", diag="n", order="hclust", hclust.method="complete")
# t-Distributed Stochastic Neighbor Embedding
tsne = Rtsne(as.matrix(train), check_duplicates=FALSE, pca=TRUE,
perplexity=30, theta=0.5, dims=2)
embedding = as.data.frame(tsne$Y)
embedding$Class = outcome.org
g = ggplot(embedding, aes(x=V1, y=V2, color=Class)) +
geom_point(size=1.25) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE 2D Embedding of 'Classe' Outcome") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank())
print(g)
# convert data to matrix
train.matrix = as.matrix(train)
mode(train.matrix) = "numeric"
test.matrix = as.matrix(test)
mode(test.matrix) = "numeric"
# convert outcome from factor to numeric matrix
#   xgboost takes multi-labels in [0, numOfClass)
y = as.matrix(as.integer(outcome)-1)
# xgboost parameters
param <- list("objective" = "multi:softprob",    # multiclass classification
"num_class" = num.class,    # number of classes
"eval_metric" = "merror",    # evaluation metric
"nthread" = 8,   # number of threads to be used
"max_depth" = 16,    # maximum depth of tree
"eta" = 0.3,    # step size shrinkage
"gamma" = 0,    # minimum loss reduction
"subsample" = 1,    # part of data instances to grow tree
"colsample_bytree" = 1,  # subsample ratio of columns when constructing each tree
"min_child_weight" = 12  # minimum sum of instance weight needed in a child
)
# set random seed, for reproducibility
set.seed(1234)
# k-fold cross validation, with timing
nround.cv = 200
system.time( bst.cv <- xgb.cv(param=param, data=train.matrix, label=y,
nfold=4, nrounds=nround.cv, prediction=TRUE, verbose=FALSE) )
tail(bst.cv$dt)
# index of minimum merror
min.merror.idx = which.min(bst.cv$dt[, test.merror.mean])
min.merror.idx
# minimum merror
bst.cv$dt[min.merror.idx,]
# get CV's prediction decoding
pred.cv = matrix(bst.cv$pred, nrow=length(bst.cv$pred)/num.class, ncol=num.class)
pred.cv = max.col(pred.cv, "last")
# confusion matrix
confusionMatrix(factor(y+1), factor(pred.cv))
